{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: (1807, 5)\n",
      "Validação: (603, 5)\n",
      "Teste: (804, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e conjunto de teste\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Dividir o conjunto de treinamento em conjunto de treinamento e conjunto de validação\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2 do total\n",
    "\n",
    "# Visualizar as dimensões dos conjuntos\n",
    "print(f'Treinamento: {train_data.shape}')\n",
    "print(f'Validação: {val_data.shape}')\n",
    "print(f'Teste: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'n_estimators': 200, 'max_depth': 10}\n",
      "Melhor acurácia: 0.8043117744610282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definindo os hiperparâmetros a serem testados\n",
    "n_estimators_options = [100, 200]\n",
    "max_depth_options = [None, 10, 20, 30]\n",
    "\n",
    "# Inicializando variáveis para armazenar os melhores resultados\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "best_rf = None\n",
    "\n",
    "# Loop sobre os hiperparâmetros\n",
    "for n_estimators in n_estimators_options:\n",
    "    for max_depth in max_depth_options:\n",
    "        # Inicializando o modelo com os hiperparâmetros atuais e random_state para reprodutibilidade\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        \n",
    "        # Treinando o modelo\n",
    "        model.fit(train_data.drop('is_ultra', axis=1), train_data['is_ultra'])\n",
    "        \n",
    "        # Fazendo previsões no conjunto de validação\n",
    "        predictions = model.predict(val_data.drop('is_ultra', axis=1))\n",
    "        \n",
    "        # Calculando a acurácia\n",
    "        accuracy = accuracy_score(val_data['is_ultra'], predictions)\n",
    "        \n",
    "        # Verificando se a acurácia atual é a melhor\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "            best_rf = model\n",
    "\n",
    "# Resultados\n",
    "print(\"Melhores hiperparâmetros:\", best_params)\n",
    "print(\"Melhor acurácia:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['calls', 'minutes', 'messages', 'mb_used', 'is_ultra'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "   print(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor resultado foi alcançado com 100 árvores. A profundidade máxima de 10 sugere que o modelo conseguiu aprender padrões significativos sem se tornar excessivamente complexo. Cerca de 80% do modelo consegue classificar corretamente o conjunto de validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros da Regressão Logística: {'C': 0.01, 'solver': 'liblinear'}\n",
      "Melhor acurácia da Regressão Logística: 0.7479270315091211\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_data.drop('is_ultra', axis=1))\n",
    "X_val_scaled = scaler.transform(val_data.drop('is_ultra', axis=1))\n",
    "\n",
    "# Definindo os hiperparâmetros a serem testados\n",
    "C_options = [0.01, 0.1, 1, 10, 100]\n",
    "solver_options = ['liblinear', 'saga']\n",
    "\n",
    "best_accuracy_logistic = 0\n",
    "best_params_logistic = {}\n",
    "\n",
    "for C in C_options:\n",
    "    for solver in solver_options:\n",
    "        model = LogisticRegression(C=C, solver=solver, max_iter=500, random_state=42)\n",
    "        model.fit(X_train_scaled, train_data['is_ultra'])\n",
    "        predictions = model.predict(X_val_scaled)\n",
    "        accuracy = accuracy_score(val_data['is_ultra'], predictions)\n",
    "        if accuracy > best_accuracy_logistic:\n",
    "            best_accuracy_logistic = accuracy\n",
    "            best_params_logistic = {'C': C, 'solver': solver}\n",
    "\n",
    "print(\"Melhores hiperparâmetros da Regressão Logística:\", best_params_logistic)\n",
    "print(\"Melhor acurácia da Regressão Logística:\", best_accuracy_logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusão: RandomForest aprensentou a acurácia significativamente melhor (80,43%) em comparação com o modelo de Regressão Logística (74,79%). Assim, se mostra mais eficaz em classificar corretamente os planos (Ultra ou Smart) com base nas características dos usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados no Conjunto de Teste:\n",
      "Acurácia: 0.8072\n",
      "Precisão: 0.7722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Fazendo previsões no conjunto de teste usando o melhor modelo Random Forest\n",
    "test_predictions = best_rf.predict(test_data.drop('is_ultra', axis=1))\n",
    "\n",
    "# Calculando as métricas de desempenho\n",
    "accuracy = accuracy_score(test_data['is_ultra'], test_predictions)\n",
    "precision = precision_score(test_data['is_ultra'], test_predictions)\n",
    "\n",
    "# Mostrando os resultados\n",
    "print(\"Resultados no Conjunto de Teste:\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados no Conjunto de Teste:\n",
      "Acurácia: 0.7600\n",
      "Precisão: 0.8429\n"
     ]
    }
   ],
   "source": [
    "# Normalizar o conjunto de teste (isso precisa estar antes do predict)\n",
    "X_test_scaled = scaler.transform(test_data.drop('is_ultra', axis=1))\n",
    "\n",
    "# Treinar o melhor modelo com os melhores hiperparâmetros\n",
    "best_model_logistic = LogisticRegression(C=best_params_logistic['C'], solver=best_params_logistic['solver'], max_iter=500, random_state=42)\n",
    "best_model_logistic.fit(X_train_scaled, train_data['is_ultra'])\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "test_predictions = best_model_logistic.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(test_data['is_ultra'], test_predictions)\n",
    "precision = precision_score(test_data['is_ultra'], test_predictions)\n",
    "\n",
    "print(\"Resultados no Conjunto de Teste:\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipótese: Apesar da Regressão Logística ter tido uma acurácia menor que da RandomForest nos hiperparâmetros, após o conjunto de teste pode se perceber que a acurácia e precisão da random forest foi significamente menor, mostrando que ela provavelemnte generalizou os dados, não sendo confiável. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
